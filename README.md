# NTAM Homework - Анализ резюме hh.ru

Этот проект состоит из двух частей:
1. Парсинг и обработка данных из CSV-файла
2. Обучение и использование регрессионной модели для предсказания зарплат

## Структура проекта

NTAM_HOMEWORK/
├── parsing_analysis/          # Часть 1: Парсинг и обработка
│   ├── app.py               # Основной скрипт парсинга
│   ├── hh_parser.py         # Парсер данных hh.ru
│   ├── pipeline.py          # Паттерн "цепочка ответственности"
│   ├── hh.csv              # Исходные данные (не в репозитории)
│   ├── processed_data.csv  # Обработанные данные
│   ├── x_data.npy          # Матрица признаков
│   └── y_data.npy          # Вектор целевой переменной
├── resources/              # Часть 2: Ресурсы модели
│   ├── model.pkl          # Обученная модель
│   ├── scaler.pkl         # Масштабатор признаков
│   ├── features.pkl       # Список признаков
│   └── feature_mapping.pkl # Соответствие признаков
├── simple_train.py        # Обучение модели
├── app.py                 # Предсказание зарплат
├── requirements.txt       # Зависимости
└── README.md              # Документация

## Часть 1: Парсинг и обработка данных

### Требования
Загрузите сырые данные. Напишите пайплайн обработки таблицы, применив паттерн проектирования "цепочка ответственности". На выходе должен быть .npy файл, готовый к дальнейшему анализу.

### Использование
```bash
cd parsing_analysis
python app.py hh.csv
```

### Результат
Скрипт создаст три файла в папке parsing_analysis/:
* x_data.npy - матрица признаков
* y_data.npy - вектор целевой переменной
* processed_data.csv - полные обработанные данные

## Часть 2: Обучение и предсказание зарплат

### Требования
На основе своего "распаршенного" датасета hh.ru обучить регрессионную модель. Приложение должно хранить веса модели в папке resources репозитория и на вход принимать выход из пайплайна, которое Вы сделали.
Установка зависимостей

### Установка зависимостей
```bash
pip install -r requirements.txt
```

### Обучение модели
```bash
python simple_train.py
```
Этот скрипт:
1. Загрузит обработанные данные из parsing_analysis/processed_data.csv
2. Обучит линейную регрессионную модель на признаках без утечки данных
3. Сохранит модель и вспомогательные файлы в папку resources/

### Предсказание зарплат
```bash
python app.py parsing_analysis/x_data.npy
```

## Особенности реализации

### Часть 1 (Парсинг):
* Использован паттерн "Chain of Responsibility" в pipeline.py
* Обработка 10 различных полей из резюме
* Создание новых признаков (группы по возрасту, опыту, взаимодействия)
* Обработка пропущенных значений

### Часть 2 (Модель):
* Использование LinearRegression из scikit-learn
* Масштабирование признаков с помощью StandardScaler
* Устранение утечки данных (исключение salary, salary_log, high_salary из признаков)
* Сохранение модели и маппинга признаков в формате pickle
* Автоматическое сопоставление признаков из x_data.npy с признаками модели
* Валидация входных данных и обработка ошибок

### Лучшие практики
* Модульная структура проекта
* Обработка ошибок и валидация входных данных
* Логирование процесса выполнения
* Читаемый и документированный код
* Разделение кода на логические модули

### Зависимости
* pandas>=1.3.0
* numpy>=1.21.0
* scikit-learn>=1.0.0
* joblib>=1.1.0